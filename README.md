# Azure OpenAI Realtime iOS Sample

[![Swift 6.0+](https://img.shields.io/badge/Swift-6.0+-orange.svg)](https://swift.org)
[![iOS 26+](https://img.shields.io/badge/iOS-26+-blue.svg)](https://developer.apple.com/ios/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A sample iOS app demonstrating real-time voice conversations with Azure OpenAI's GPT-4o Realtime API using WebRTC.

![App Screenshot](docs/screenshot.png)
<!-- TODO: Add actual screenshot before launch -->

## Features

- ğŸ¤ **Real-time voice conversations** with GPT-4o
- ğŸ“ **Live transcription** of both user and assistant speech
- ğŸ’¾ **Conversation history** persisted with SwiftData
- ğŸ”Š **Multiple voice options** (Alloy, Echo, Shimmer, etc.)
- ğŸ“¤ **Share transcripts** via iOS share sheet

## Quick Start

### Prerequisites

- macOS 14.0+ with Xcode 16.0+
- Python 3.11+
- Azure subscription with [Azure OpenAI access](https://learn.microsoft.com/azure/ai-services/openai/overview)

### 1. Clone and Configure Backend

```bash
git clone https://github.com/YOUR_USERNAME/realtime-api.git
cd realtime-api/backend

# Setup Python environment
python3 -m venv .venv && source .venv/bin/activate
pip install -e .

# Configure Azure credentials
cp .env.example .env
# Edit .env with your Azure OpenAI credentials
```

### 2. Start the Token Service

```bash
uvicorn main:app --reload
```

Verify it's running: `curl http://localhost:8000/health`

### 3. Run the iOS App

1. Open `realtime-api.xcodeproj` in Xcode
2. Select your development team (Signing & Capabilities)
3. Run on Simulator (âŒ˜R)

For detailed setup instructions, see [Getting Started Guide](docs/GETTING_STARTED.md).

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        iOS App                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   SwiftUI    â”‚â—„â”€â”€â–ºâ”‚  ViewModel   â”‚â—„â”€â”€â–ºâ”‚  SwiftData   â”‚  â”‚
â”‚  â”‚    Views     â”‚    â”‚              â”‚    â”‚  (SQLite)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                    â”‚  RealtimeAPI    â”‚                     â”‚
â”‚                    â”‚  (WebRTC)       â”‚                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚               â”‚               â”‚
              â–¼               â–¼               â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
     â”‚ Token Backend  â”‚  â”‚ Azure      â”‚      â”‚
     â”‚ (FastAPI)      â”‚  â”‚ OpenAI     â”‚â—„â”€â”€â”€â”€â”€â”˜
     â”‚ /api/v1/token  â”‚  â”‚ Realtime   â”‚  WebRTC audio
     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Azure OpenAI   â”‚
     â”‚ /client_secretsâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components:**

| Component | Technology | Purpose |
|-----------|------------|---------|
| iOS App | SwiftUI, SwiftData | Voice conversation UI |
| ViewModel | Swift, async/await | Business logic, API integration |
| RealtimeAPI | WebRTC | Real-time audio streaming |
| Token Backend | Python, FastAPI | Secure token generation |

## Project Structure

```
realtime-api/
â”œâ”€â”€ realtime-api/              # iOS app source
â”‚   â”œâ”€â”€ Models/                # SwiftData entities
â”‚   â”œâ”€â”€ ViewModels/            # Business logic
â”‚   â”œâ”€â”€ Views/                 # SwiftUI views
â”‚   â””â”€â”€ Services/              # API clients
â”œâ”€â”€ backend/                   # Python token service
â”‚   â”œâ”€â”€ main.py               # FastAPI app
â”‚   â””â”€â”€ .env.example          # Environment template
â””â”€â”€ docs/                      # Documentation
    â””â”€â”€ GETTING_STARTED.md    # Setup guide
```

## Configuration

### Backend Environment Variables

| Variable | Description |
|----------|-------------|
| `AZURE_OPENAI_ENDPOINT` | Your Azure OpenAI resource URL |
| `AZURE_OPENAI_API_KEY` | API key from Azure Portal |
| `AZURE_OPENAI_DEPLOYMENT` | Deployment name (e.g., `gpt-4o-realtime-preview`) |
| `AZURE_OPENAI_TRANSCRIPTION_MODEL` | Whisper model for transcription |

### iOS Configuration

The app automatically connects to `http://127.0.0.1:8000` on Simulator. For physical devices, set `BACKEND_URL` in the Xcode scheme environment variables.

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## Resources

- [Azure OpenAI Realtime API Documentation](https://learn.microsoft.com/azure/ai-services/openai/realtime-audio-quickstart)
- [swift-realtime-openai Package](backend/swift-realtime-openai/README.md)
- [SwiftUI Documentation](https://developer.apple.com/documentation/swiftui)

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
